{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Ultimate Guide To Speech Recognition With Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hướng dẫn\n",
    "# https://realpython.com/python-speech-recognition/\n",
    "# sample audio files\n",
    "# https://github.com/realpython/python-speech-recognition/tree/master/audio_files\n",
    "# https://convertio.co/aac-wav/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using speech_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nn7fr\\\\Dropbox\\\\share\\\\nvnkrus\\\\advanced-python\\\\speech_recognition'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.chdir('./speech_recognition')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'speech_recognition.Recognizer'> <class 'speech_recognition.AudioFile'> <class 'speech_recognition.audio.AudioData'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the stale smell of old beer lingers it takes heat to bring out the odor a cold dip restores health and zest a salt pickle taste fine with ham tacos al pastor are my favorite a zestful food is the hot cross bun'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = sr.Recognizer()             # recognizer for speech recognition\n",
    "fname = os.path.join('audio_files', 'harvard.wav')\n",
    "harvard = sr.AudioFile(fname)   # audio object\n",
    "with harvard as source:         # audio data\n",
    "    audio = r.record(source)\n",
    "print(type(r),type(harvard),type(audio))\n",
    "r.recognize_google(audio) # english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'speech_recognition.Recognizer'> <class 'speech_recognition.AudioFile'> <class 'speech_recognition.audio.AudioData'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Chồng yêu ơi chồng ở nhà chưa'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://cloud.google.com/speech-to-text/docs/speech-to-text-supported-languages\n",
    "r = sr.Recognizer()             # recognizer for speech recognition\n",
    "fname = os.path.join('audio_files', 'ngoctram_voice_001.wav')\n",
    "harvard = sr.AudioFile(fname)   # audio object\n",
    "with harvard as source:         # audio data\n",
    "    audio = r.record(source)\n",
    "print(type(r),type(harvard),type(audio))\n",
    "r.recognize_google(audio,language='vi-VI') # vietnamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method recognize_legacy in module speech_recognition.recognizers.google:\n",
      "\n",
      "recognize_legacy(audio_data: 'AudioData', key: 'str | None' = None, language: 'str' = 'en-US', pfilter: 'ProfanityFilterLevel' = 0, show_all: 'bool' = False, with_confidence: 'bool' = False) method of speech_recognition.Recognizer instance\n",
      "    Performs speech recognition on ``audio_data`` (an ``AudioData`` instance), using the Google Speech Recognition API.\n",
      "    \n",
      "    The Google Speech Recognition API key is specified by ``key``. If not specified, it uses a generic key that works out of the box. This should generally be used for personal or testing purposes only, as it **may be revoked by Google at any time**.\n",
      "    \n",
      "    To obtain your own API key, simply following the steps on the `API Keys <http://www.chromium.org/developers/how-tos/api-keys>`__ page at the Chromium Developers site. In the Google Developers Console, Google Speech Recognition is listed as \"Speech API\".\n",
      "    \n",
      "    The recognition language is determined by ``language``, an RFC5646 language tag like ``\"en-US\"`` (US English) or ``\"fr-FR\"`` (International French), defaulting to US English. A list of supported language tags can be found in this `StackOverflow answer <http://stackoverflow.com/a/14302134>`__.\n",
      "    \n",
      "    The profanity filter level can be adjusted with ``pfilter``: 0 - No filter, 1 - Only shows the first character and replaces the rest with asterisks. The default is level 0.\n",
      "    \n",
      "    Returns the most likely transcription if ``show_all`` is false (the default). Otherwise, returns the raw API response as a JSON dictionary.\n",
      "    \n",
      "    Raises a ``speech_recognition.UnknownValueError`` exception if the speech is unintelligible. Raises a ``speech_recognition.RequestError`` exception if the speech recognition operation failed, if the key isn't valid, or if there is no internet connection.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(r.recognize_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydub import AudioSegment\n",
    "\n",
    "# # Load AAC audio from file (replace with your actual file path)\n",
    "# fname = os.path.join('audio_files', 'ngoctram_voice_001.aac')\n",
    "# aac_audio = AudioSegment.from_file(fname, format=\"aac\")\n",
    "\n",
    "# # Export to WAV format\n",
    "# fname = os.path.join('audio_files', 'ngoctram_voice_001.wav')\n",
    "# aac_audio.export(fname, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from guessing_game import recognize_speech_from_mic\n",
    "r = sr.Recognizer()\n",
    "m = sr.Microphone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True, 'error': 'Unable to recognize speech', 'transcription': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognize_speech_from_mic(r, m)  # speak after running this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft Sound Mapper - Input',\n",
       " 'Microphone (A4tech FHD 1080P PC',\n",
       " 'Microsoft Sound Mapper - Output',\n",
       " '헤드폰 (Realtek(R) Audio)',\n",
       " '스피커 (Realtek(R) Audio)',\n",
       " 'Primary Sound Capture Driver',\n",
       " 'Microphone (A4tech FHD 1080P PC Camera)',\n",
       " 'Primary Sound Driver',\n",
       " '헤드폰 (Realtek(R) Audio)',\n",
       " '스피커 (Realtek(R) Audio)',\n",
       " '스피커 (Realtek(R) Audio)',\n",
       " '헤드폰 (Realtek(R) Audio)',\n",
       " 'Microphone (A4tech FHD 1080P PC Camera)',\n",
       " 'Headphones (Realtek HD Audio 2nd output)',\n",
       " 'Microphone (Realtek HD Audio Mic input)',\n",
       " 'Speakers (Realtek HD Audio output)',\n",
       " 'Stereo Mix (Realtek HD Audio Stereo input)',\n",
       " 'Headphones ()',\n",
       " 'Headset (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free%0\\r\\n;(Nhan’s AirPods Pro))',\n",
       " 'Headset (@System32\\\\drivers\\\\bthhfenum.sys,#2;%1 Hands-Free%0\\r\\n;(Nhan’s AirPods Pro))',\n",
       " 'Microphone (A4tech FHD 1080P PC Camera)',\n",
       " 'Output (@System32\\\\drivers\\\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\\r\\n;(NIPHONE))',\n",
       " 'Input (@System32\\\\drivers\\\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\\r\\n;(NIPHONE))',\n",
       " 'Input ()',\n",
       " 'Input ()',\n",
       " 'Output (@System32\\\\drivers\\\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\\r\\n;(Galaxy S7))',\n",
       " 'Input (@System32\\\\drivers\\\\bthhfenum.sys,#4;%1 Hands-Free HF Audio%0\\r\\n;(Galaxy S7))']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = sr.Microphone(device_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'muốn tạo một bức tranh trong đó có một con đường Ron đang chạy trên một cánh đồng để cắt để thu hoạch những trái cây'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with m as source:\n",
    "    audio = r.listen(source)\n",
    "r.recognize_google(audio,language='vi-VI') # vietnamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using VietAI ASR\n",
    "https://github.com/vietai/ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nn7fr\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at nguyenvulebinh/wav2vec2-base-vietnamese-250h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at nguyenvulebinh/wav2vec2-base-vietnamese-250h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nn7fr\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load model and tokenizer\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"nguyenvulebinh/wav2vec2-base-vietnamese-250h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"nguyenvulebinh/wav2vec2-base-vietnamese-250h\")\n",
    "\n",
    "# define function to read in sound file\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "# load dummy dataset and read soundfiles\n",
    "ds = map_to_array({\n",
    "    \"file\": 'audio_files/ngoctram_voice_001.wav'\n",
    "})\n",
    "\n",
    "# tokenize\n",
    "input_values = processor(ds[\"speech\"], return_tensors=\"pt\", padding=\"longest\").input_values  # Batch size 1\n",
    "\n",
    "# retrieve logits\n",
    "logits = model(input_values).logits\n",
    "\n",
    "# take argmax and decode\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.batch_decode(predicted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thần n đưa ra thần gán hàn xợ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
